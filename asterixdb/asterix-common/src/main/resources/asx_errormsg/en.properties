#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

# Error code:
# 0 --- 999:  runtime errors
# 1000 ---- 1999: compilation errors
# 2000 ---- 2999: storage errors
# 3000 ---- 3999: feed errors
# 4000 ---- 4999: lifecycle management errors

# For the extension lifecycle
4001 = Two Extensions share the same Id: %1$s
4002 = Extension Conflict between %1$s and %2$s both extensions extend %3$s
4003 = Unsupported message type: %1$s
4004 = Invalid configuration: %1$s
4005 = Unsupported replication strategy %1$s

# Type errors
2,1002 = Type mismatch: function %1$s expects its %2$s input parameter to be type %3$s, but the actual input type is %4$s
3,1003 = Type incompatibility: function %1$s gets incompatible input values: %2$s and %3$s
4,1004 = Unsupported type: %1$s cannot process input type %2$s
5,1005 = Invalid item type: function %1$s cannot process item type %2$s in an input array (or multiset)
13,1006 = Duplicate field name \"%1$s\"
1009 = A returning expression cannot contain dataset access

# Data errors
6 = Invalid format for %1$s in %2$s
7 = Overflow happend in %1$s
8 = Underflow happend in %1$s
9 = Injected failure in %1$s
10 = Invalid value: function %1$s expects its %2$s input parameter to be a non-negative value, but gets %3$s
11 = Index out of bound in %1$s: %2$s
12 = Invalid implicit scalar to collection coercion in %1$s
14 = Property %1$s not set
100 = Unable to instantiate class %1$s

# Compile-time check errors
1007 = Invalid expression: function %1$s expects its %2$s input parameter to be a %3$s expression, but the actual expression is %4$s
1008 = Invalid parameter number: function %1$s cannot take %2$s parameters
1010 = Phrase search in Full-text is not yet supported. Only one keyword per expression is permitted
1011 = Unknown dataset type %1$s
1012 = Unknown index type %1$s
1013 = Cannot use %1$s fields as a key for the %2$s index. The index can only support keys of size %3$s
1014 = Field \"%1$s\" is not found
1015 = Index of type %1$s is not supported for dataset \"%2$s\" since it has composite primary keys
1016 = Index of type %1$s is not supported for dataset of type %2$s
1017 = The filter field \"%1$s\" cannot be an optional field
1018 = Field of type %1$s cannot be used as a filter field
1019 = Cannot autogenerate a composite primary key
1020 = Cannot autogenerate a primary key for primary key of type %1$s. Autogenerated primary keys must be of type %2$s
1021 = The primary key field \"%1$s\" cannot be nullable
1022 = Field of type %1$s cannot be used as a primary key field
1023 = Can't drop dataset %1$s since it is connected to active entity: %2$s
1024 = Identifier %1$s is not found in AQL+ meta-scope
1025 = There is no such join type in AQL+
1026 = A parser error has occured. The detail exception: %1$s

# Feed Errors
3001 = Illegal state.
3002 = Tuple is too large for a frame
3003 = Unknown tuple forward policy
3004 = Unable to create adapter as class loader not configured for library %1$s in dataverse %2$s
3005 = At record: %1$s - Field %2$s is not privatean optional type so it cannot accept null value.
3006 = Illegal field %1$s in closed type %2$s
3007 = Failure in active job.
3008 = Unable to ingest data
3009 = Invalid subscribable runtime type %1$s
3010 = Doesn't support Hive data with list of non-primitive types
3011 = Can't get hive type for field of type %1$s
3012 = Failed to get columns of record
3013 = Can't deserialize Hive records with no closed columns
3014 = Non-optional UNION type is not supported.
3015 = Failed to get the type information for field %1$s.
3016 = can't parse null field
3017 = can't parse hive list with null values
3018 = Field %1$s of meta record is not an optional type so it cannot accept null value.
3019 = Can't get PK from record part
3020 = Feed joint %1$s already registered
3021 = Could not register feed intake job [%1$s] for feed  %2$s
3022 = Unknown data source type: %1$s
3023 = Unknown input stream factory: %1$s
3024 = Failed to create stream factory
3025 = Unknown record reader factory: %1$s
3026 = Unknown format: %1$s
3027 = Unknown record format for a record with meta parser. Did you specify the parameter %1$s
3028 = Field already defined in %1$s part
3029 = Unknown field: %1$s
3031 = No node controllers found at the address: %1$s
3032 = Unable to resolve hostname '%1$s' to an IP address
3033 = Unknown DCP request: %1$s
3034 = Attempt to register to a failed feed data provider
3035 = Feed already has an intake job
3036 = Feed job already registered in intake jobs
3037 = Feed job already registered in all jobs
3038 = Record is too large!. Maximum record size is %1$s
3039 = Cannot parse list item of type %1$s
3040 = Argument type: %1$s
3041 = Unable to load/instantiate class %1$s
3042 = UDF of kind %1$s not supported.
3043 = Unknown function kind %1$s
3044 = Library class loader already registered!
3045 = Cannot handle a function argument of type %1$s
3046 = Object of type %1$s not supported.
3047 = External %1$s not supported
3048 = Invalid feed runtime: %1$s
3049 = '%1$s' is not a valid delimiter. The length of a delimiter should be 1.
3050 = '%1$s' is not a valid quote. The length of a quote should be 1.
3051 = Quote '%1$s' cannot be used with the delimiter '%2$s'.
3052 = Was not able to find a file in the files index
3053 = Field %1$s can not be null
3054 = Mismatch Type, expecting a value of type %1$s
3055 = Unexpected ADM token kind: %1$s.
3056 = Illegal escape '\%1$s'
3057 = Found END_RECORD while expecting a record field.
3058 = This record is closed, you can not add extra fields! new field name: %1$s
3059 = Unexpected ADM token kind: %1$s while expecting ":".
3060 = Found COMMA %1$s %2$s record field.
3061 = Unsupported interval type: %1$s.
3062 = Interval was not closed.
3063 = The interval start and end point types do not match: %1$s != %2$s
3064 = Missing COMMA before interval end point.
3065 = This can not be an instance of interval: missing T for a datetime value.
3066 = Unsupported interval type: %1$s.
3067 = Interval argument not properly constructed.
3068 = Found END_COLLECTION while expecting a list item.
3069 = Found COMMA before any list item.
3070 = Found COMMA while expecting a list item.
3071 = Found END_RECORD while expecting a list item.
3072 = Can't cast the %1$s type to the %2$s type.
3073 = Missing deserializer method for constructor: %1$s.
3074 = This can not be an instance of %1$s
3075 = Closed field %1$s has null value.
3076 = %1$s: no files found
3077 = %1$s: path not found
3078 = Cannot obtain hdfs scheduler
